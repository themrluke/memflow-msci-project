name: spanet_labframe
version: v2-gluon-dist-redo4
description: 'Like v2-eregr with gluon losses'
input_dataset_train: /eos/user/d/dvalsecc/www/ttHbbAnalysis/training_dataset/v3_sig_forTrainingDataset/all_jets_fullRun2_ttHbb_forTraining_allyears_spanetprov_part1_train.parquet
input_dataset_validation: /eos/user/d/dvalsecc/www/ttHbbAnalysis/training_dataset/v3_sig_forTrainingDataset/all_jets_fullRun2_ttHbb_forTraining_allyears_spanetprov_part1_validation.parquet
input_dataset_test: /eos/user/d/dvalsecc/www/ttHbbAnalysis/training_dataset/v3_sig_forTrainingDataset/all_jets_fullRun2_ttHbb_forTraining_allyears_spanetprov_part2.parquet       
cartesian: false
ddp_port: 12346
noProv: true
input_shape:
  number_jets: 16
  number_lept: 1
  input_features: 7  # now with 3 prov probabilities
scaling_params:
  log_mean: [4.6710e+00, 2.8028e-05, 7.9478e-04]
  log_std: [0.9195, 1.2910, 1.8139]
training_params:
  dtype: "float64"
  lr: 0.0005
  batch_size_training: 1024
  batch_size_validation: 2048
  subsplit: 8
  nepochs: 1000
  training_sample: 0.9
  validation_sample: 0.1
  sampling_points_loss: 150
  percentage_sampling_epoch: 0.2
  sampling_points: 100
  nEpochsPatience: 40
  eps: 1.0e-05
  mmd_kernel: "multiscale"
  huber_delta: 1.
  order:
  - 0
  - 1
  - 2
  - 3
  sampling_Forward: false
  reduce_on_plateau:
    factor: 0.5
    patience: 5
    threshold: 1e-3
  cosine_scheduler:
    after_N_epochs: 10
    Tmax : 15
    eta_min: 3e-5
conditioning_transformer:
  out_features: [3,3,3,1]
  hidden_features: 64
  dim_feedforward_transformer: 512
  nhead_encoder: 8
  no_layers_encoder: 4
  nhead_decoder: 4
  no_layers_decoder: 4
  aggregate: false
  no_decoders: 4
  use_latent: true
  no_layers_decoder_latent: 2
  out_features_latent: 6
unfolding_flow:
  nfeatures: 10
  ncond: 32
  ntransforms: 10
  hiddenMLP_NoLayers: 4
  hiddenMLP_LayerDim: 128
  bins: 35
  autoregressive: false
  base: DiagNormal
  base_first_arg: 0
  base_second_arg: 0.3
  bound: 1.5
MDMM:
  max_mmd: 0.001
  scale_mmd : 1
  dumping_mmd: 1.

comet_token: uaitssszWuWAaWQkBrDXdlJBt
