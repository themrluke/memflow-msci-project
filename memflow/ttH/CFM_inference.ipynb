{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20f754e5-5310-4717-8700-8dc85ecf889f",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a7bc2a-42e5-48ff-8ddd-a01ed240d9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import awkward as ak\n",
    "import pandas as pd\n",
    "import dask\n",
    "from tqdm import tqdm\n",
    "\n",
    "import vector\n",
    "import particle\n",
    "import hepunits\n",
    "\n",
    "import comet_ml\n",
    "import zuko\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import lightning as L\n",
    "from lightning.pytorch import loggers as pl_loggers\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.optim.lr_scheduler import SequentialLR, LambdaLR, CosineAnnealingLR\n",
    "\n",
    "import multiprocessing\n",
    "import uuid\n",
    "\n",
    "from memflow.dataset.data import ParquetData\n",
    "from memflow.dataset.dataset import CombinedDataset\n",
    "from memflow.ttH.ttH_dataclasses import ttHHardDataset, ttHRecoDataset\n",
    "\n",
    "from memflow.ttH.models.TransferCFM import StandardCFM, OptimalTransportCFM, TargetBridgingCFM, SchrodingerBridgeCFM, VariancePreservingCFM\n",
    "from models.utils import plot_trajectories_2d, compare_distributions, save_samples, load_samples, plot_trajectories_grid\n",
    "from models.callbacks import CFMSamplingCallback, SamplingCallback, BiasCallback\n",
    "\n",
    "vector.register_awkward()\n",
    "\n",
    "num_workers = min(16, multiprocessing.cpu_count())  # Use up to 16 CPU cores\n",
    "print(f'Number of CPU workers for dataloading: {num_workers}')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"  # Change \"<n>\" to the index of the GPU you want to use on node\n",
    "\n",
    "print (f\"Running on GPU : {torch.cuda.is_available()}\")\n",
    "accelerator = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print (f\"Accelerator : {accelerator}\")\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "if accelerator =='cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "    print (torch.cuda.memory_summary(device=None, abbreviated=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c50d80-9342-47c6-9efd-87c39a91bc5b",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a68956-c2a9-4fbd-b11a-9025f8339cb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_hard = ParquetData(\n",
    "    files = [\n",
    "        '/cephfs/dice/users/sa21722/datasets/MEM_data/ttH/TF_v6/hard/2018/ttH/ttH_HToInvisible_M125.parquet',\n",
    "        #'all_jets_fullRun2_ttHbb_forTraining_allyears_spanetprov_part1_validation.parquet',\n",
    "        #'all_jets_fullRun2_ttHTobb_forTraining_2016_PreVFP_v3.parquet',\n",
    "    ],\n",
    "    lazy = True,\n",
    "    # N = int(1e5),\n",
    ")\n",
    "\n",
    "print (data_hard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35dfc61-246f-444b-930a-e5cdd77fd3c9",
   "metadata": {},
   "source": [
    "# Hard dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd35299-f40b-4864-9132-67a95e03acd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hard_dataset = ttHHardDataset(\n",
    "    data = data_hard,\n",
    "    selection = [\n",
    "        # 'higgs',\n",
    "        # 'tops',\n",
    "        'bottoms',\n",
    "        # 'Ws',\n",
    "        # 'Zs',\n",
    "        'quarks',\n",
    "        'neutrinos',\n",
    "    ],\n",
    "    build = False,\n",
    "    fit = True,\n",
    "    coordinates = 'cylindrical',\n",
    "    apply_preprocessing = True,\n",
    "    apply_boost = False,\n",
    "    dtype = torch.float32,\n",
    ")\n",
    "\n",
    "print(hard_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c19d008-7658-4b9e-b3c1-463ec3401a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Before preprocessing')\n",
    "hard_dataset.plot(selection=True,raw=True)\n",
    "print ('After preprocessing')\n",
    "hard_dataset.plot(selection=True,raw=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c82aff-8a32-4f83-b199-0c7725639eda",
   "metadata": {},
   "source": [
    "# Reco dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc523344",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reco = ParquetData(\n",
    "    files = [\n",
    "        '/cephfs/dice/users/sa21722/datasets/MEM_data/ttH/TF_v6/reco/2018/ttH/ttH_HToInvisible_M125.parquet',\n",
    "    ],\n",
    "    lazy = True,\n",
    "    #N = data_hard.N,\n",
    ")\n",
    "\n",
    "print(data_reco)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ece5f1",
   "metadata": {},
   "source": [
    "Have a look at athe minimum values for Jet and MET pT in the raw dataset. This can give an indication as to what the cutoff in the SR is and hence what to set the `'pt':lowercutshift()` to in the pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e781dae8-05ad-462e-b91a-bc544337a39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reco_dataset = ttHRecoDataset(\n",
    "    data = data_reco,\n",
    "    selection = [\n",
    "        'jets',\n",
    "        'met',\n",
    "    ],\n",
    "    build = False,\n",
    "    fit = True,\n",
    "    coordinates = 'cylindrical',\n",
    "    apply_preprocessing = True,\n",
    "    apply_boost = False,\n",
    "    dtype = torch.float32,\n",
    ")\n",
    "print(reco_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a0ac35-78bf-45a7-ab31-d1d8884f4844",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Before preprocessing')\n",
    "reco_dataset.plot(selection=True,raw=True,log=True)\n",
    "print ('After preprocessing')\n",
    "reco_dataset.plot(selection=True,raw=False,log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dc702e-66b1-450a-86d0-a28192f99d98",
   "metadata": {},
   "source": [
    "# Combined dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12a63d7-eafc-43ef-8147-d0887d4bceec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_dataset = CombinedDataset(\n",
    "    hard_dataset=hard_dataset,\n",
    "    reco_dataset=reco_dataset,\n",
    ")\n",
    "print(combined_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76acc7c1-02e8-4c7f-8354-69090de0a9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_loader = DataLoader(\n",
    "    combined_dataset,\n",
    "    batch_size = 10000,\n",
    "    shuffle = False,\n",
    "    num_workers = num_workers,\n",
    "    pin_memory = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0848b68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StandardCFM.load_from_checkpoint(checkpoint_path=\"trained_standardCFM/model_epoch_500.ckpt\")\n",
    "model.to(accelerator)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e440a8-85ba-4044-8f44-e094e6a58347",
   "metadata": {},
   "source": [
    "# TransferCFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaf5d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(inference_loader))\n",
    "batch = CFMSamplingCallback.move_batch_to_device(batch, model.device)\n",
    "# Print the structure of the batch\n",
    "print(\"Batch structure:\")\n",
    "for key in batch:\n",
    "    print(f\"{key}:\")\n",
    "    for sub_key, val in batch[key].items():\n",
    "        if isinstance(val, list):\n",
    "            print(f\"  {sub_key}: {[v.shape for v in val]}\")\n",
    "        elif isinstance(val, torch.Tensor):\n",
    "            print(f\"  {sub_key}: {val.shape}\")\n",
    "\n",
    "traj_samples_file = \"traj_samples.pt\"\n",
    "all_traj_file = \"all_traj.pt\"\n",
    "if os.path.exists(os.path.join(\"saved_samples\", traj_samples_file)) and os.path.exists(os.path.join(\"saved_samples\", all_traj_file)):\n",
    "    traj_samples = load_samples(traj_samples_file)\n",
    "    all_traj = load_samples(all_traj_file)\n",
    "else:\n",
    "    with torch.no_grad():\n",
    "        model = model.to(model.device)\n",
    "\n",
    "        # Extract the necessary inputs for sampling\n",
    "        hard_data = batch[\"hard\"][\"data\"]\n",
    "        hard_mask = batch[\"hard\"][\"mask\"]\n",
    "        reco_data = batch[\"reco\"][\"data\"]\n",
    "        reco_mask = batch[\"reco\"][\"mask\"]\n",
    "\n",
    "        print(f\"Hard data batch size: {hard_data[0].shape[0]}\")\n",
    "        print(f\"Reco data batch size: {reco_data[0].shape[0]}\")\n",
    "\n",
    "        traj_samples, all_traj = model.sample(\n",
    "            hard_data,\n",
    "            hard_mask,\n",
    "            reco_data,\n",
    "            reco_mask,\n",
    "            N_sample=1000,\n",
    "            steps=20,\n",
    "            store_trajectories=True\n",
    "        )\n",
    "    save_samples(traj_samples, traj_samples_file)\n",
    "    save_samples(all_traj, all_traj_file)\n",
    "    # Took 12 mins for 100 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e07bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_traj is the shape [N_sample, steps+1, B, sum_reco, 2], used for 2D trajectory plots\n",
    "# Feature indexes:\n",
    "#   Jets: \"pt\"=0, \"eta\"=1 \"phi\"=2\n",
    "#   MET: \"pt\"=0, \"phi\"=1\n",
    "plot_trajectories_2d(\n",
    "    all_traj,\n",
    "    model,\n",
    "    type_idx = 1, # \"Jets\"=0, \"met\"=1\n",
    "    feat_idx_x = 1,\n",
    "    feat_idx_y = 0,\n",
    "    num_events = 1000,\n",
    "    mode = \"single_event\",\n",
    "    event_idx = 1,\n",
    "    object_idx = 0,\n",
    "    preprocessing = combined_dataset.reco_dataset.preprocessing,\n",
    "    batch=batch,\n",
    ")\n",
    "plot_trajectories_2d(\n",
    "    all_traj,\n",
    "    model,\n",
    "    type_idx = 0, # \"Jets\"=0, \"met\"=1\n",
    "    feat_idx_x = 1,\n",
    "    feat_idx_y = 0,\n",
    "    num_events = 1000,\n",
    "    mode = \"single_event\",\n",
    "    event_idx = 1,\n",
    "    object_idx = 3,\n",
    "    preprocessing = combined_dataset.reco_dataset.preprocessing,\n",
    "    batch=batch,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d0e5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectories_grid(\n",
    "    all_traj,\n",
    "    model,\n",
    "    custom_timesteps=[1, 10, 15, 19],\n",
    "    type_idx=0,\n",
    "    feat_idx_x=0,\n",
    "    feat_idx_y=1,\n",
    "    max_points=10,\n",
    "    event_idx=1,\n",
    "    object_idx=2,\n",
    "    batch=batch,\n",
    "    grid_size=14\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f4dd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract real and generated data for comparison\n",
    "# traj_samples shape: [particle type, num samples, num events, num particles, num features] e.g.[2, 1, 10000, 6, 3]\n",
    "real_data = batch[\"reco\"][\"data\"] # Shape: [particle type, num events, num particles, num features] e.g.[2, 10000, 6, 5]\n",
    "\n",
    "# Jet Feature indexes:\n",
    "#   real: \"pt\"=0, \"eta\"=1 \"phi\"=2\n",
    "#   gen: \"pt\"=0, \"eta\"=1 \"phi\"=2\n",
    "compare_distributions(real_data[0], traj_samples[0], real_feat_idx=0, gen_feat_idx=0, feat_name=\"Jets pt\")\n",
    "compare_distributions(real_data[0], traj_samples[0],  real_feat_idx=1, gen_feat_idx=1, feat_name=\"Jets eta\")\n",
    "compare_distributions(real_data[0], traj_samples[0],  real_feat_idx=2, gen_feat_idx=2, feat_name=\"Jets phi\")\n",
    "\n",
    "# MET Feature indexes:\n",
    "#   real: \"pt\"=0, \"phi\"=2\n",
    "#   gen: \"pt\"=0, \"phi\"=1\n",
    "compare_distributions(real_data[1], traj_samples[1], real_feat_idx=0, gen_feat_idx=0, feat_name=\"MET pt\")\n",
    "compare_distributions(real_data[1], traj_samples[1], real_feat_idx=2, gen_feat_idx=1, feat_name=\"MET phi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a654eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks to make plots within comet\n",
    "bias = BiasCallback(\n",
    "    dataset = combined_dataset,               # dataset on which to evaluate bias\n",
    "    preprocessing = combined_dataset.reco_dataset.preprocessing, # preprocessing pipeline to draw raw variables\n",
    "    N_sample = 100, #100                                # number of samples to draw\n",
    "    steps = 20,                                     # Number of bridging steps\n",
    "    store_trajectories = False,                     # To save trajectories plots\n",
    "    frequency = 50,                                 # plotting frequency (epochs)\n",
    "    raw = True,\n",
    "    bins = 101,                                      # 1D/2D plot number of bins\n",
    "    points = 20,                                    # Number of points for the quantile\n",
    "    log_scale = True,                               # log\n",
    "    batch_size = 1000, #1000                         # Batch size to evaluate the dataset (internally makes a loaded)\n",
    "    N_batch = 1,                                   # Stop after N batches (makes it faster)\n",
    "    suffix = 'ttH',                                 # name for plots\n",
    "    label_names = {                             # makes nicer labels\n",
    "        'pt' : 'p_T',\n",
    "        'eta' : '\\eta',\n",
    "        'phi' : '\\phi',\n",
    "    },\n",
    ")\n",
    "\n",
    "sampling = SamplingCallback(\n",
    "    dataset = combined_dataset,           # dataset to check sampling\n",
    "    preprocessing = combined_dataset.reco_dataset.preprocessing, # preprocessing pipeline\n",
    "    idx_to_monitor = [1,2,3,4,5,6,7,8,9,10],               # idx of events in dataset to make plots with\n",
    "    N_sample = 10000,                          # number of samples to draw\n",
    "    steps = 20,                                     # Number of bridging steps\n",
    "    store_trajectories = False,                     # To save trajectories plots\n",
    "    frequency = 50,                             # plotting frequency (epochs)\n",
    "    bins = 101,                                  # 1D/2D plot number of bins\n",
    "    log_scale = True,                           # log\n",
    "    label_names = {                             # makes nicer labels\n",
    "        'pt' : r'$p_T$ [GeV]',\n",
    "        'eta' : r'$\\eta$',\n",
    "        'phi' : r'$\\phi$ [rad]',\n",
    "    },\n",
    "    pt_range = 500,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a7a91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_file = \"samples.pt\"\n",
    "if os.path.exists(os.path.join(\"saved_samples\", samples_file)):\n",
    "    samples = load_samples(samples_file)\n",
    "else:\n",
    "    device = model.device\n",
    "    sampling.set_idx(sampling.idx_to_monitor)\n",
    "    hard_data = [d.to(device) for d in sampling.batch['hard']['data']]\n",
    "    hard_mask = [m.to(device) for m in sampling.batch['hard']['mask']]\n",
    "    reco_data = [d.to(device) for d in sampling.batch['reco']['data']]\n",
    "    reco_mask = [m.to(device) for m in sampling.batch['reco']['mask']]\n",
    "\n",
    "    print(f\"Hard data batch size: {hard_data[0].shape[0]}\")\n",
    "    print(f\"Reco data batch size: {reco_data[0].shape[0]}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model = model.to(model.device)\n",
    "        samples = model.sample(\n",
    "                            hard_data, hard_mask,\n",
    "                            reco_data, reco_mask,\n",
    "                            sampling.N_sample,\n",
    "                            sampling.steps,\n",
    "                            sampling.store_trajectories\n",
    "                        )\n",
    "    save_samples(samples, samples_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54eb8ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "figures = sampling.make_sampling_plots(model,show=True,external_samples=samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39c6236",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device=model.device\n",
    "\n",
    "bias_samples_file = \"bias_samples.pt\"\n",
    "if os.path.exists(os.path.join(\"saved_samples\", bias_samples_file)):\n",
    "    bias_samples = load_samples(bias_samples_file)\n",
    "else:\n",
    "    for batch_idx, batch in tqdm(enumerate(bias.loader),desc='Predict',disable=False,leave=True,total=min(bias.N_batch,len(bias.loader)),position=0):\n",
    "        if batch_idx >= bias.N_batch:\n",
    "            break\n",
    "\n",
    "        # Get parts #\n",
    "        hard_data = [data.to(device) for data in batch['hard']['data']]\n",
    "        hard_mask_exist = [mask.to(device) for mask in batch['hard']['mask']]\n",
    "        reco_data = [data.to(device) for data in batch['reco']['data']]\n",
    "        reco_mask_exist = [mask.to(device) for mask in batch['reco']['mask']]\n",
    "\n",
    "        print(f\"Hard data batch size: {hard_data[0].shape[0]}\")\n",
    "        print(f\"Reco data batch size: {reco_data[0].shape[0]}\")\n",
    "\n",
    "        # Sample #\n",
    "        with torch.no_grad():\n",
    "            bias_samples = model.sample(\n",
    "                hard_data, hard_mask_exist,\n",
    "                reco_data, reco_mask_exist,\n",
    "                bias.N_sample,\n",
    "                bias.steps,\n",
    "                bias.store_trajectories,\n",
    "            )\n",
    "        #save_samples(bias_samples, bias_samples_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977b4a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "figs = bias.make_bias_plots(model,show=True,)#external_samples=bias_samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mem-flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
