{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20f754e5-5310-4717-8700-8dc85ecf889f",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a7bc2a-42e5-48ff-8ddd-a01ed240d9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import awkward as ak\n",
    "import pandas as pd\n",
    "import dask\n",
    "from tqdm import tqdm\n",
    "\n",
    "import vector\n",
    "import particle\n",
    "import hepunits\n",
    "\n",
    "import comet_ml\n",
    "import zuko\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import lightning as L\n",
    "from lightning.pytorch import loggers as pl_loggers\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "import multiprocessing\n",
    "import uuid\n",
    "\n",
    "from memflow.dataset.data import ParquetData\n",
    "from memflow.dataset.dataset import CombinedDataset\n",
    "from memflow.ttH.ttH_dataclasses import ttHHardDataset, ttHRecoDataset\n",
    "\n",
    "from memflow.ttH.models.TransferCFM import StandardCFM as TransferCFM\n",
    "from memflow.ttH.models.Transfusion import StandardCFM as Transfusion\n",
    "from memflow.ttH.models.ParallelTransfusion import StandardCFM as ParallelTransfusion\n",
    "from memflow.ttH.models.TransferCFM_original import StandardCFM as OriginalCFM\n",
    "\n",
    "from memflow.ttH.distribution_plots import *\n",
    "from models.utils import load_samples, save_samples\n",
    "from models.callbacks import SamplingCallback, BiasCallback\n",
    "\n",
    "from transfer_flow.transfer_flow_model import *\n",
    "from transfer_flow.custom_flows import *\n",
    "\n",
    "vector.register_awkward()\n",
    "\n",
    "num_workers = min(16, multiprocessing.cpu_count())  # Use up to 16 CPU cores\n",
    "print(f'Number of CPU workers for dataloading: {num_workers}')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"  # Change \"<n>\" to the index of the GPU you want to use on node\n",
    "\n",
    "print (f\"Running on GPU : {torch.cuda.is_available()}\")\n",
    "accelerator = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print (f\"Accelerator : {accelerator}\")\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "if accelerator =='cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "    print (torch.cuda.memory_summary(device=None, abbreviated=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c50d80-9342-47c6-9efd-87c39a91bc5b",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a68956-c2a9-4fbd-b11a-9025f8339cb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_hard = ParquetData(\n",
    "    files = [\n",
    "        '/cephfs/dice/users/sa21722/datasets/MEM_data/ttH/TF_v6/hard/2018/ttH/ttH_HToInvisible_M125.parquet',\n",
    "        #'all_jets_fullRun2_ttHbb_forTraining_allyears_spanetprov_part1_validation.parquet',\n",
    "        #'all_jets_fullRun2_ttHTobb_forTraining_2016_PreVFP_v3.parquet',\n",
    "    ],\n",
    "    lazy = True,\n",
    "    # N = int(1e5),\n",
    ")\n",
    "\n",
    "print (data_hard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35dfc61-246f-444b-930a-e5cdd77fd3c9",
   "metadata": {},
   "source": [
    "# Hard dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd35299-f40b-4864-9132-67a95e03acd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hard_dataset = ttHHardDataset(\n",
    "    data = data_hard,\n",
    "    selection = [\n",
    "        # 'higgs',\n",
    "        # 'tops',\n",
    "        'bottoms',\n",
    "        # 'Ws',\n",
    "        # 'Zs',\n",
    "        'quarks',\n",
    "        'neutrinos',\n",
    "    ],\n",
    "    build = False,\n",
    "    fit = True,\n",
    "    coordinates = 'cylindrical',\n",
    "    apply_preprocessing = True,\n",
    "    apply_boost = False,\n",
    "    dtype = torch.float32,\n",
    ")\n",
    "\n",
    "print(hard_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c82aff-8a32-4f83-b199-0c7725639eda",
   "metadata": {},
   "source": [
    "# Reco dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc523344",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reco = ParquetData(\n",
    "    files = [\n",
    "        '/cephfs/dice/users/sa21722/datasets/MEM_data/ttH/TF_v6/reco/2018/ttH/ttH_HToInvisible_M125.parquet',\n",
    "    ],\n",
    "    lazy = True,\n",
    "    #N = data_hard.N,\n",
    ")\n",
    "\n",
    "print(data_reco)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ece5f1",
   "metadata": {},
   "source": [
    "Have a look at athe minimum values for Jet and MET pT in the raw dataset. This can give an indication as to what the cutoff in the SR is and hence what to set the `'pt':lowercutshift()` to in the pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e781dae8-05ad-462e-b91a-bc544337a39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reco_dataset = ttHRecoDataset(\n",
    "    data = data_reco,\n",
    "    selection = [\n",
    "        'jets',\n",
    "        'met',\n",
    "    ],\n",
    "    build = False,\n",
    "    fit = True,\n",
    "    coordinates = 'cylindrical',\n",
    "    apply_preprocessing = True,\n",
    "    apply_boost = False,\n",
    "    dtype = torch.float32,\n",
    ")\n",
    "print(reco_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dc702e-66b1-450a-86d0-a28192f99d98",
   "metadata": {},
   "source": [
    "# Combined dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12a63d7-eafc-43ef-8147-d0887d4bceec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_dataset = CombinedDataset(\n",
    "    hard_dataset=hard_dataset,\n",
    "    reco_dataset=reco_dataset,\n",
    ")\n",
    "\n",
    "train_frac = 0.8\n",
    "indices = torch.arange(len(combined_dataset))\n",
    "sep = int(train_frac*len(combined_dataset))\n",
    "valid_indices = indices[sep:]\n",
    "combined_dataset_valid = torch.utils.data.Subset(combined_dataset,valid_indices)\n",
    "print (f'Dataset : validation {len(combined_dataset_valid)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48b78ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "TransferCFM_model = TransferCFM.load_from_checkpoint(checkpoint_path=\"trained_model_checkpoints/TransferCFM_checkpoints/model_epoch_500.ckpt\")\n",
    "TransferCFM_model.to(accelerator)\n",
    "TransferCFM_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb9be53",
   "metadata": {},
   "outputs": [],
   "source": [
    "ParallelTransfusion_model = ParallelTransfusion.load_from_checkpoint(checkpoint_path=\"trained_model_checkpoints/parallel_transfusion_checkpoints/model_epoch_500.ckpt\")\n",
    "ParallelTransfusion_model.to(accelerator)\n",
    "ParallelTransfusion_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f045f518",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfermer_model = TransferFlow.load_from_checkpoint(\n",
    "    checkpoint_path=\"trained_model_checkpoints/TransferFlow_checkpoints/model_epoch_500.ckpt\",\n",
    "    encoder_embeddings=MultiEmbeddings(\n",
    "        features_per_type=combined_dataset.hard_dataset.input_features,\n",
    "        embed_dims=[32, 64],\n",
    "        hidden_activation=nn.GELU,\n",
    "    ),\n",
    "    decoder_embeddings=MultiEmbeddings(\n",
    "        features_per_type=combined_dataset.reco_dataset.input_features,\n",
    "        embed_dims=[32, 64],\n",
    "        hidden_activation=nn.GELU,\n",
    "    ),\n",
    "    transformer=Transformer(\n",
    "        d_model=64,\n",
    "        encoder_layers=6,\n",
    "        decoder_layers=8,\n",
    "        nhead=8,\n",
    "        dim_feedforward=256,\n",
    "        activation=nn.GELU,\n",
    "        encoder_mask_attn=None,\n",
    "        decoder_mask_attn=combined_dataset.reco_dataset.attention_mask,\n",
    "        use_null_token=True,\n",
    "        dropout=0.0,\n",
    "    ),\n",
    "    flow=KinematicFlow(\n",
    "        d_model=64,\n",
    "        flow_mode='global',\n",
    "        flow_features=[\n",
    "            ['pt', 'eta', 'phi', 'mass'],  # jets\n",
    "            ['pt', 'phi'],  # met\n",
    "        ],\n",
    "        flow_classes={\n",
    "            'pt': zuko.flows.NSF,\n",
    "            'eta': UniformNSF,\n",
    "            'phi': UniformNCSF,\n",
    "            'mass': zuko.flows.NSF,\n",
    "        },\n",
    "        flow_common_args={\n",
    "            'bins': 16,\n",
    "            'transforms': 5,\n",
    "            'randperm': True,\n",
    "            'passes': None,\n",
    "            'hidden_features': [256] * 3,\n",
    "        },\n",
    "        flow_specific_args={\n",
    "            'eta': {'bound': 1.0},\n",
    "            'phi': {'bound': math.pi},\n",
    "        },\n",
    "    ),\n",
    ")\n",
    "transfermer_model.to(accelerator)\n",
    "transfermer_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bccf3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks to make plots within comet\n",
    "bias = BiasCallback(\n",
    "    dataset = combined_dataset_valid,               # dataset on which to evaluate bias\n",
    "    preprocessing = combined_dataset.reco_dataset.preprocessing, # preprocessing pipeline to draw raw variables\n",
    "    N_sample = 2,                                 # number of samples to draw\n",
    "    steps = 20,                                     # Number of bridging steps\n",
    "    store_trajectories = False,                     # To save trajectories plots\n",
    "    frequency = 50,                                 # plotting frequency (epochs)\n",
    "    bins = 101,                                      # 1D/2D plot number of bins\n",
    "    points = 20,                                    # Number of points for the quantile\n",
    "    log_scale = True,                               # log\n",
    "    batch_size = 100,                              # Batch size to evaluate the dataset (internally makes a loaded)\n",
    "    #N_batch = 20,                                   # Stop after N batches (makes it faster)\n",
    "    suffix = 'ttH',                                 # name for plots\n",
    "    label_names = {                             # makes nicer labels\n",
    "        'pt' : 'p_T',\n",
    "        'eta' : '\\eta',\n",
    "        'phi' : '\\phi',\n",
    "    },\n",
    ")\n",
    "\n",
    "sampling = SamplingCallback(\n",
    "    dataset = combined_dataset_valid,           # dataset to check sampling\n",
    "    preprocessing = combined_dataset.reco_dataset.preprocessing, # preprocessing pipeline\n",
    "    idx_to_monitor = [1,2,3,4,5,6,7,8,9,10],               # idx of events in dataset to make plots with\n",
    "    N_sample = 10000,                          # number of samples to draw\n",
    "    steps = 20,                                     # Number of bridging steps\n",
    "    store_trajectories = False,                     # To save trajectories plots\n",
    "    frequency = 50,                             # plotting frequency (epochs)\n",
    "    bins = 31,                                  # 1D/2D plot number of bins\n",
    "    log_scale = True,                           # log\n",
    "    label_names = {                             # makes nicer labels\n",
    "        'pt' : r'$p_T$ [GeV]',\n",
    "        'eta' : r'$\\eta$',\n",
    "        'phi' : r'$\\phi$ [rad]',\n",
    "    },\n",
    "    pt_range = 350,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002915a7",
   "metadata": {},
   "source": [
    "# Transfermer per event sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654ab4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfermer_samples_file = \"Transfermer_samples2.pt\"\n",
    "\n",
    "if os.path.exists(os.path.join(\"saved_samples\", transfermer_samples_file)):\n",
    "    transfermer_samples = load_samples(transfermer_samples_file)\n",
    "else:\n",
    "    device = transfermer_model.device\n",
    "    sampling.set_idx(sampling.idx_to_monitor)\n",
    "\n",
    "    # Move input data to the correct device\n",
    "    hard_data = [d.to(device) for d in sampling.batch['hard']['data']]\n",
    "    hard_mask = [m.to(device) for m in sampling.batch['hard']['mask']]\n",
    "    reco_data = [d.to(device) for d in sampling.batch['reco']['data']]\n",
    "    reco_mask = [m.to(device) for m in sampling.batch['reco']['mask']]\n",
    "\n",
    "    print(f\"Hard data batch size: {hard_data[0].shape[0]}\")\n",
    "    print(f\"Reco data batch size: {reco_data[0].shape[0]}\")\n",
    "\n",
    "    # Number of samples per event\n",
    "    total_samples = sampling.N_sample  \n",
    "    batch_size = 10  # Number of samples per batch to avoid memory issues\n",
    "    num_batches = (total_samples + batch_size - 1) // batch_size  # Ensure full coverage\n",
    "\n",
    "    # Storage for results\n",
    "    accumulated_samples = [None, None]  \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx in tqdm(range(num_batches), desc=\"Sampling batches\", unit=\"batch\"):\n",
    "            # Determine the number of samples to generate in this batch\n",
    "            current_N = min(batch_size, total_samples - batch_idx * batch_size)\n",
    "\n",
    "            # Generate samples\n",
    "            batch_samples = transfermer_model.sample(\n",
    "                hard_data,\n",
    "                hard_mask,\n",
    "                reco_data,\n",
    "                reco_mask,\n",
    "                N=current_N\n",
    "            )\n",
    "\n",
    "            # Feature selection\n",
    "            jets_indices = [0, 1, 2, 3]  # ['pt', 'eta', 'phi', 'mass']\n",
    "            met_indices = [0, 2]         # ['pt', 'phi']\n",
    "\n",
    "            batch_samples[0] = batch_samples[0][..., jets_indices]  # Filter jet features\n",
    "            batch_samples[1] = batch_samples[1][..., met_indices]   # Filter MET features\n",
    "\n",
    "            # Accumulate results\n",
    "            if accumulated_samples[0] is None:\n",
    "                accumulated_samples[0] = batch_samples[0].cpu()\n",
    "                accumulated_samples[1] = batch_samples[1].cpu()\n",
    "            else:\n",
    "                accumulated_samples[0] = torch.cat((accumulated_samples[0], batch_samples[0].cpu()), dim=0)\n",
    "                accumulated_samples[1] = torch.cat((accumulated_samples[1], batch_samples[1].cpu()), dim=0)\n",
    "\n",
    "    # Convert final results to the expected format\n",
    "    transfermer_samples = accumulated_samples\n",
    "\n",
    "    # Debugging prints\n",
    "    num_items = len(transfermer_samples)\n",
    "    print(f\"Number of elements per sample: {num_items}\")\n",
    "    for i, sample in enumerate(transfermer_samples):\n",
    "        print(f\"Sample {i}: {sample.shape}\")\n",
    "\n",
    "    # Save the concatenated samples\n",
    "    save_samples(transfermer_samples, transfermer_samples_file)\n",
    "\n",
    "# 3mins 27s, 10 events, 10000 samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b604adc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "figures = sampling.make_sampling_plots(ParallelTransfusion_model,external_samples=transfermer_samples, cmap='RdPu', save_dir='sampling_plots/transfermer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc20a255",
   "metadata": {},
   "source": [
    "# Parallel Transfusion per event sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26816b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "PT_samples_file = \"PT_samples2.pt\"\n",
    "if os.path.exists(os.path.join(\"saved_samples\", PT_samples_file)):\n",
    "    PT_samples = load_samples(PT_samples_file)\n",
    "else:\n",
    "    device = ParallelTransfusion_model.device\n",
    "    sampling.set_idx(sampling.idx_to_monitor)\n",
    "    hard_data = [d.to(device) for d in sampling.batch['hard']['data']]\n",
    "    hard_mask = [m.to(device) for m in sampling.batch['hard']['mask']]\n",
    "    reco_data = [d.to(device) for d in sampling.batch['reco']['data']]\n",
    "    reco_mask = [m.to(device) for m in sampling.batch['reco']['mask']]\n",
    "\n",
    "    print(f\"Hard data batch size: {hard_data[0].shape[0]}\")\n",
    "    print(f\"Reco data batch size: {reco_data[0].shape[0]}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model = ParallelTransfusion_model.to(ParallelTransfusion_model.device)\n",
    "        PT_samples = model.sample(\n",
    "                            hard_data, hard_mask,\n",
    "                            reco_data, reco_mask,\n",
    "                            sampling.N_sample,\n",
    "                            sampling.steps,\n",
    "                            sampling.store_trajectories\n",
    "                        )\n",
    "    # Debugging prints\n",
    "    num_items = len(PT_samples)\n",
    "    print(f\"Number of elements per sample: {num_items}\")\n",
    "    for i, sample in enumerate(PT_samples):\n",
    "        print(f\"Sample {i}: {sample.shape}\")\n",
    "    save_samples(PT_samples, PT_samples_file)\n",
    "\n",
    "# 42mins 14s for 10 events, 10000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2b4682",
   "metadata": {},
   "outputs": [],
   "source": [
    "figures = sampling.make_sampling_plots(ParallelTransfusion_model,external_samples=PT_samples, cmap='BuGn', save_dir='sampling_plots/parallel_transfusion')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9260f69",
   "metadata": {},
   "source": [
    "# Transfer-CFM per event sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4d1837",
   "metadata": {},
   "outputs": [],
   "source": [
    "TransferCFM_samples_file = \"TransferCFM_samples2.pt\"\n",
    "if os.path.exists(os.path.join(\"saved_samples\", TransferCFM_samples_file)):\n",
    "    TransferCFM_samples = load_samples(TransferCFM_samples_file)\n",
    "else:\n",
    "    device = ParallelTransfusion_model.device\n",
    "    sampling.set_idx(sampling.idx_to_monitor)\n",
    "    hard_data = [d.to(device) for d in sampling.batch['hard']['data']]\n",
    "    hard_mask = [m.to(device) for m in sampling.batch['hard']['mask']]\n",
    "    reco_data = [d.to(device) for d in sampling.batch['reco']['data']]\n",
    "    reco_mask = [m.to(device) for m in sampling.batch['reco']['mask']]\n",
    "\n",
    "    print(f\"Hard data batch size: {hard_data[0].shape[0]}\")\n",
    "    print(f\"Reco data batch size: {reco_data[0].shape[0]}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model = TransferCFM_model.to(TransferCFM_model.device)\n",
    "        TransferCFM_samples = model.sample(\n",
    "                            hard_data, hard_mask,\n",
    "                            reco_data, reco_mask,\n",
    "                            sampling.N_sample,\n",
    "                            sampling.steps,\n",
    "                            sampling.store_trajectories\n",
    "                        )\n",
    "    # Debugging prints\n",
    "    num_items = len(TransferCFM_samples)\n",
    "    print(f\"Number of elements per sample: {num_items}\")\n",
    "    for i, sample in enumerate(TransferCFM_samples):\n",
    "        print(f\"Sample {i}: {sample.shape}\")\n",
    "    save_samples(TransferCFM_samples, TransferCFM_samples_file)\n",
    "\n",
    "# 11mins 25s for 10 events, 10000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7f8513",
   "metadata": {},
   "outputs": [],
   "source": [
    "figures = sampling.make_sampling_plots(TransferCFM_model,external_samples=TransferCFM_samples, cmap='BuPu', save_dir='sampling_plots/transferCFM')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdd913e",
   "metadata": {},
   "source": [
    "# Bias Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52943be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predict:   0%|          | 0/184 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predict: 100%|██████████| 184/184 [00:43<00:00,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples saved to saved_samples/Transfermer_bias_samples.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = transfermer_model.device\n",
    "\n",
    "transfermer_bias_samples_file = \"Transfermer_bias_samples.pt\"\n",
    "\n",
    "if os.path.exists(os.path.join(\"saved_samples\", transfermer_bias_samples_file)):\n",
    "    transfermer_bias_samples = load_samples(transfermer_bias_samples_file)\n",
    "\n",
    "else:\n",
    "    accumulated_samples = [[], []] # Two types of reco-level particle\n",
    "    for batch_idx, batch in tqdm(enumerate(bias.loader),desc='Predict',disable=False,leave=True,total=min(bias.N_batch,len(bias.loader)),position=0):\n",
    "\n",
    "        # Move batch data to device\n",
    "        hard_data = [data.to(device) for data in batch['hard']['data']]\n",
    "        hard_mask_exist = [mask.to(device) for mask in batch['hard']['mask']]\n",
    "        reco_data = [data.to(device) for data in batch['reco']['data']]\n",
    "        reco_mask_exist = [mask.to(device) for mask in batch['reco']['mask']]\n",
    "\n",
    "        # Sample\n",
    "        with torch.no_grad():\n",
    "            transfermer_bias_samples = transfermer_model.sample(\n",
    "                hard_data, hard_mask_exist,\n",
    "                reco_data, reco_mask_exist,\n",
    "                bias.N_sample,\n",
    "            )\n",
    "            # Feature selection\n",
    "            jets_indices = [0, 1, 2, 3]  # ['pt', 'eta', 'phi', 'mass']\n",
    "            met_indices = [0, 2]         # ['pt', 'phi']\n",
    "\n",
    "            transfermer_bias_samples[0] = transfermer_bias_samples[0][..., jets_indices]  # Filter jet features\n",
    "            transfermer_bias_samples[1] = transfermer_bias_samples[1][..., met_indices]   # Filter MET features\n",
    "\n",
    "        # Accumulate samples across batches\n",
    "        accumulated_samples[0].append(transfermer_bias_samples[0].cpu())  # Move to CPU to free GPU memory\n",
    "        accumulated_samples[1].append(transfermer_bias_samples[1].cpu())\n",
    "\n",
    "    # Concatenate accumulated samples along the batch dimension\n",
    "    transfermer_bias_samples = [torch.cat(accumulated_samples[0], dim=1),  # Concatenate along batch axis\n",
    "                                torch.cat(accumulated_samples[1], dim=1)]\n",
    "    save_samples(transfermer_bias_samples, transfermer_bias_samples_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4fb2161b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predict: 100%|██████████| 184/184 [00:00<00:00, 333.07it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [36728] at index 0 does not match the shape of the indexed tensor [6757952, 1] at index 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m figs \u001b[38;5;241m=\u001b[39m \u001b[43mbias\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_bias_plots\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParallelTransfusion_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43mshow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mexternal_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransfermer_bias_samples\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cephfs/dice/users/sa21722/projects/MEM/memflow/ttH/models/callbacks.py:1008\u001b[0m, in \u001b[0;36mBiasCallback.make_bias_plots\u001b[0;34m(self, model, show, disable_tqdm, external_samples)\u001b[0m\n\u001b[1;32m   1000\u001b[0m         flow_fields \u001b[38;5;241m=\u001b[39m [fields[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mflow_indices[i]]\n\u001b[1;32m   1001\u001b[0m         truth[i], _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39minverse(\n\u001b[1;32m   1002\u001b[0m             name \u001b[38;5;241m=\u001b[39m name,\n\u001b[1;32m   1003\u001b[0m             x \u001b[38;5;241m=\u001b[39m truth[i],\n\u001b[1;32m   1004\u001b[0m             mask \u001b[38;5;241m=\u001b[39m mask[i],\n\u001b[1;32m   1005\u001b[0m             fields \u001b[38;5;241m=\u001b[39m flow_fields,\n\u001b[1;32m   1006\u001b[0m         )\n\u001b[0;32m-> 1008\u001b[0m         samples[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocessing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m            \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mN_sample\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mN_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mN_sample\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfields\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mflow_fields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN_sample,samples[i]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],samples[i]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m],samples[i]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;66;03m# Make the different plots\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m figs \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/cephfs/dice/users/sa21722/projects/MEM/memflow/dataset/preprocessing.py:175\u001b[0m, in \u001b[0;36mPreprocessingPipeline.inverse\u001b[0;34m(self, name, x, mask, fields)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step\u001b[38;5;241m.\u001b[39mapplies(name):\n\u001b[0;32m--> 175\u001b[0m         x,fields \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x,fields\n",
      "File \u001b[0;32m/cephfs/dice/users/sa21722/projects/MEM/memflow/dataset/preprocessing.py:390\u001b[0m, in \u001b[0;36mPreprocessingStep.inverse\u001b[0;34m(self, name, x, mask, fields)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minverse\u001b[39m(\u001b[38;5;28mself\u001b[39m,name,x,mask,fields):\n\u001b[0;32m--> 390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minverse\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cephfs/dice/users/sa21722/projects/MEM/memflow/dataset/preprocessing.py:366\u001b[0m, in \u001b[0;36mPreprocessingStep._process\u001b[0;34m(self, name, x, mask, fields, direction)\u001b[0m\n\u001b[1;32m    364\u001b[0m     proc_field \u001b[38;5;241m=\u001b[39m [proc_field[\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m    365\u001b[0m \u001b[38;5;66;03m# Change the values but only unmasked particles #\u001b[39;00m\n\u001b[0;32m--> 366\u001b[0m xp[mp] \u001b[38;5;241m=\u001b[39m \u001b[43mxs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmp\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;66;03m# Record #\u001b[39;00m\n\u001b[1;32m    368\u001b[0m xps\u001b[38;5;241m.\u001b[39mappend(xp\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mIndexError\u001b[0m: The shape of the mask [36728] at index 0 does not match the shape of the indexed tensor [6757952, 1] at index 0"
     ]
    }
   ],
   "source": [
    "figs = bias.make_bias_plots(ParallelTransfusion_model,show=True,external_samples=transfermer_bias_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beaf32d",
   "metadata": {},
   "source": [
    "## Parallel Transfusion Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4699478",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predict:  18%|█▊        | 33/184 [00:19<01:27,  1.72it/s]"
     ]
    }
   ],
   "source": [
    "device = ParallelTransfusion_model.device\n",
    "\n",
    "PT_bias_samples_file = \"PT_bias_samples.pt\"\n",
    "\n",
    "if os.path.exists(os.path.join(\"saved_samples\", PT_bias_samples_file)):\n",
    "    PT_bias_samples = load_samples(PT_bias_samples_file)\n",
    "\n",
    "else:\n",
    "    accumulated_samples = [[], []] # Two types of reco-level particle\n",
    "    for batch_idx, batch in tqdm(enumerate(bias.loader),desc='Predict',disable=False,leave=True,total=min(bias.N_batch,len(bias.loader)),position=0):\n",
    "\n",
    "        # Move batch data to device\n",
    "        hard_data = [data.to(device) for data in batch['hard']['data']]\n",
    "        hard_mask_exist = [mask.to(device) for mask in batch['hard']['mask']]\n",
    "        reco_data = [data.to(device) for data in batch['reco']['data']]\n",
    "        reco_mask_exist = [mask.to(device) for mask in batch['reco']['mask']]\n",
    "\n",
    "        # Sample\n",
    "        with torch.no_grad():\n",
    "            PT_bias_samples = ParallelTransfusion_model.sample(\n",
    "                hard_data, hard_mask_exist,\n",
    "                reco_data, reco_mask_exist,\n",
    "                bias.N_sample,\n",
    "                bias.steps,\n",
    "                bias.store_trajectories\n",
    "            )\n",
    "\n",
    "        # Accumulate samples across batches\n",
    "        accumulated_samples[0].append(PT_bias_samples[0].cpu())  # Move to CPU to free GPU memory\n",
    "        accumulated_samples[1].append(PT_bias_samples[1].cpu())\n",
    "\n",
    "    # Concatenate accumulated samples along the batch dimension\n",
    "    PT_bias_samples = [torch.cat(accumulated_samples[0], dim=1),  # Concatenate along batch axis\n",
    "                       torch.cat(accumulated_samples[1], dim=1)]\n",
    "\n",
    "    save_samples(PT_bias_samples, PT_bias_samples_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b4de03",
   "metadata": {},
   "outputs": [],
   "source": [
    "figs = bias.make_bias_plots(ParallelTransfusion_model,show=True,external_samples=PT_bias_samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mem-flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
