{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20f754e5-5310-4717-8700-8dc85ecf889f",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a7bc2a-42e5-48ff-8ddd-a01ed240d9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import awkward as ak\n",
    "import pandas as pd\n",
    "import dask\n",
    "from tqdm import tqdm\n",
    "\n",
    "import vector\n",
    "import particle\n",
    "import hepunits\n",
    "\n",
    "import comet_ml\n",
    "import zuko\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import lightning as L\n",
    "from lightning.pytorch import loggers as pl_loggers\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "import multiprocessing\n",
    "import uuid\n",
    "\n",
    "from memflow.dataset.data import ParquetData\n",
    "from memflow.dataset.dataset import CombinedDataset\n",
    "from memflow.ttH.ttH_dataclasses import ttHHardDataset, ttHRecoDataset\n",
    "\n",
    "from memflow.ttH.models.TransferCFM import StandardCFM as TransferCFM\n",
    "from memflow.ttH.models.Transfusion import StandardCFM as Transfusion\n",
    "from memflow.ttH.models.ParallelTransfusion import StandardCFM as ParallelTransfusion\n",
    "from memflow.ttH.models.TransferCFM_original import StandardCFM as OriginalCFM\n",
    "\n",
    "from memflow.ttH.distribution_plots import *\n",
    "from models.utils import load_samples, save_samples\n",
    "from models.callbacks import SamplingCallback, BiasCallback\n",
    "\n",
    "from transfer_flow.transfer_flow_model import *\n",
    "from transfer_flow.custom_flows import *\n",
    "\n",
    "vector.register_awkward()\n",
    "\n",
    "num_workers = min(16, multiprocessing.cpu_count())  # Use up to 16 CPU cores\n",
    "print(f'Number of CPU workers for dataloading: {num_workers}')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"  # Change \"<n>\" to the index of the GPU you want to use on node\n",
    "\n",
    "print (f\"Running on GPU : {torch.cuda.is_available()}\")\n",
    "accelerator = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print (f\"Accelerator : {accelerator}\")\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "if accelerator =='cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "    print (torch.cuda.memory_summary(device=None, abbreviated=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c50d80-9342-47c6-9efd-87c39a91bc5b",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a68956-c2a9-4fbd-b11a-9025f8339cb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_hard = ParquetData(\n",
    "    files = [\n",
    "        '/cephfs/dice/users/sa21722/datasets/MEM_data/ttH/TF_v6/hard/2018/ttH/ttH_HToInvisible_M125.parquet',\n",
    "        #'all_jets_fullRun2_ttHbb_forTraining_allyears_spanetprov_part1_validation.parquet',\n",
    "        #'all_jets_fullRun2_ttHTobb_forTraining_2016_PreVFP_v3.parquet',\n",
    "    ],\n",
    "    lazy = True,\n",
    "    # N = int(1e5),\n",
    ")\n",
    "\n",
    "print (data_hard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35dfc61-246f-444b-930a-e5cdd77fd3c9",
   "metadata": {},
   "source": [
    "# Hard dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd35299-f40b-4864-9132-67a95e03acd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hard_dataset = ttHHardDataset(\n",
    "    data = data_hard,\n",
    "    selection = [\n",
    "        # 'higgs',\n",
    "        # 'tops',\n",
    "        'bottoms',\n",
    "        # 'Ws',\n",
    "        # 'Zs',\n",
    "        'quarks',\n",
    "        'neutrinos',\n",
    "    ],\n",
    "    build = False,\n",
    "    fit = True,\n",
    "    coordinates = 'cylindrical',\n",
    "    apply_preprocessing = True,\n",
    "    apply_boost = False,\n",
    "    dtype = torch.float32,\n",
    ")\n",
    "\n",
    "print(hard_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c82aff-8a32-4f83-b199-0c7725639eda",
   "metadata": {},
   "source": [
    "# Reco dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc523344",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reco = ParquetData(\n",
    "    files = [\n",
    "        '/cephfs/dice/users/sa21722/datasets/MEM_data/ttH/TF_v6/reco/2018/ttH/ttH_HToInvisible_M125.parquet',\n",
    "    ],\n",
    "    lazy = True,\n",
    "    #N = data_hard.N,\n",
    ")\n",
    "\n",
    "print(data_reco)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ece5f1",
   "metadata": {},
   "source": [
    "Have a look at athe minimum values for Jet and MET pT in the raw dataset. This can give an indication as to what the cutoff in the SR is and hence what to set the `'pt':lowercutshift()` to in the pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e781dae8-05ad-462e-b91a-bc544337a39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reco_dataset = ttHRecoDataset(\n",
    "    data = data_reco,\n",
    "    selection = [\n",
    "        'jets',\n",
    "        'met',\n",
    "    ],\n",
    "    build = False,\n",
    "    fit = True,\n",
    "    coordinates = 'cylindrical',\n",
    "    apply_preprocessing = True,\n",
    "    apply_boost = False,\n",
    "    dtype = torch.float32,\n",
    ")\n",
    "print(reco_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dc702e-66b1-450a-86d0-a28192f99d98",
   "metadata": {},
   "source": [
    "# Combined dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12a63d7-eafc-43ef-8147-d0887d4bceec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_dataset = CombinedDataset(\n",
    "    hard_dataset=hard_dataset,\n",
    "    reco_dataset=reco_dataset,\n",
    ")\n",
    "\n",
    "train_frac = 0.8\n",
    "indices = torch.arange(len(combined_dataset))\n",
    "sep = int(train_frac*len(combined_dataset))\n",
    "valid_indices = indices[sep:]\n",
    "combined_dataset_valid = torch.utils.data.Subset(combined_dataset,valid_indices)\n",
    "print (f'Dataset : validation {len(combined_dataset_valid)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48b78ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "TransferCFM_model = TransferCFM.load_from_checkpoint(checkpoint_path=\"trained_model_checkpoints/TransferCFM_checkpoints/model_epoch_500.ckpt\")\n",
    "TransferCFM_model.to(accelerator)\n",
    "TransferCFM_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb9be53",
   "metadata": {},
   "outputs": [],
   "source": [
    "ParallelTransfusion_model = ParallelTransfusion.load_from_checkpoint(checkpoint_path=\"trained_model_checkpoints/parallel_transfusion_checkpoints/model_epoch_500.ckpt\")\n",
    "ParallelTransfusion_model.to(accelerator)\n",
    "ParallelTransfusion_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f045f518",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfermer_model = TransferFlow.load_from_checkpoint(\n",
    "    checkpoint_path=\"trained_model_checkpoints/TransferFlow_checkpoints/model_epoch_500.ckpt\",\n",
    "    encoder_embeddings=MultiEmbeddings(\n",
    "        features_per_type=combined_dataset.hard_dataset.input_features,\n",
    "        embed_dims=[32, 64],\n",
    "        hidden_activation=nn.GELU,\n",
    "    ),\n",
    "    decoder_embeddings=MultiEmbeddings(\n",
    "        features_per_type=combined_dataset.reco_dataset.input_features,\n",
    "        embed_dims=[32, 64],\n",
    "        hidden_activation=nn.GELU,\n",
    "    ),\n",
    "    transformer=Transformer(\n",
    "        d_model=64,\n",
    "        encoder_layers=6,\n",
    "        decoder_layers=8,\n",
    "        nhead=8,\n",
    "        dim_feedforward=256,\n",
    "        activation=nn.GELU,\n",
    "        encoder_mask_attn=None,\n",
    "        decoder_mask_attn=combined_dataset.reco_dataset.attention_mask,\n",
    "        use_null_token=True,\n",
    "        dropout=0.0,\n",
    "    ),\n",
    "    flow=KinematicFlow(\n",
    "        d_model=64,\n",
    "        flow_mode='global',\n",
    "        flow_features=[\n",
    "            ['pt', 'eta', 'phi', 'mass'],  # jets\n",
    "            ['pt', 'phi'],  # met\n",
    "        ],\n",
    "        flow_classes={\n",
    "            'pt': zuko.flows.NSF,\n",
    "            'eta': UniformNSF,\n",
    "            'phi': UniformNCSF,\n",
    "            'mass': zuko.flows.NSF,\n",
    "        },\n",
    "        flow_common_args={\n",
    "            'bins': 16,\n",
    "            'transforms': 5,\n",
    "            'randperm': True,\n",
    "            'passes': None,\n",
    "            'hidden_features': [256] * 3,\n",
    "        },\n",
    "        flow_specific_args={\n",
    "            'eta': {'bound': 1.0},\n",
    "            'phi': {'bound': math.pi},\n",
    "        },\n",
    "    ),\n",
    ")\n",
    "transfermer_model.to(accelerator)\n",
    "transfermer_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bccf3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks to make plots within comet\n",
    "bias = BiasCallback(\n",
    "    dataset = combined_dataset_valid,               # dataset on which to evaluate bias\n",
    "    preprocessing = combined_dataset.reco_dataset.preprocessing, # preprocessing pipeline to draw raw variables\n",
    "    N_sample = 100,                                 # number of samples to draw\n",
    "    steps = 20,                                     # Number of bridging steps\n",
    "    store_trajectories = False,                     # To save trajectories plots\n",
    "    frequency = 50,                                 # plotting frequency (epochs)\n",
    "    bins = 101,                                      # 1D/2D plot number of bins\n",
    "    points = 20,                                    # Number of points for the quantile\n",
    "    log_scale = True,                               # log\n",
    "    batch_size = 1000,                              # Batch size to evaluate the dataset (internally makes a loaded)\n",
    "    #N_batch = 20,                                   # Stop after N batches (makes it faster)\n",
    "    suffix = 'ttH',                                 # name for plots\n",
    "    label_names = {                             # makes nicer labels\n",
    "        'pt' : 'p_T',\n",
    "        'eta' : '\\eta',\n",
    "        'phi' : '\\phi',\n",
    "    },\n",
    ")\n",
    "\n",
    "sampling = SamplingCallback(\n",
    "    dataset = combined_dataset_valid,           # dataset to check sampling\n",
    "    preprocessing = combined_dataset.reco_dataset.preprocessing, # preprocessing pipeline\n",
    "    idx_to_monitor = [1,2,3,4,5,6,7,8,9,10],               # idx of events in dataset to make plots with\n",
    "    N_sample = 10000,                          # number of samples to draw\n",
    "    steps = 20,                                     # Number of bridging steps\n",
    "    store_trajectories = False,                     # To save trajectories plots\n",
    "    frequency = 50,                             # plotting frequency (epochs)\n",
    "    bins = 31,                                  # 1D/2D plot number of bins\n",
    "    log_scale = True,                           # log\n",
    "    label_names = {                             # makes nicer labels\n",
    "        'pt' : r'$p_T$ [GeV]',\n",
    "        'eta' : r'$\\eta$',\n",
    "        'phi' : r'$\\phi$ [rad]',\n",
    "    },\n",
    "    pt_range = 350,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002915a7",
   "metadata": {},
   "source": [
    "# Transfermer per event sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654ab4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfermer_samples_file = \"Transfermer_samples2.pt\"\n",
    "\n",
    "if os.path.exists(os.path.join(\"saved_samples\", transfermer_samples_file)):\n",
    "    transfermer_samples = load_samples(transfermer_samples_file)\n",
    "else:\n",
    "    device = transfermer_model.device\n",
    "    sampling.set_idx(sampling.idx_to_monitor)\n",
    "\n",
    "    # Move input data to the correct device\n",
    "    hard_data = [d.to(device) for d in sampling.batch['hard']['data']]\n",
    "    hard_mask = [m.to(device) for m in sampling.batch['hard']['mask']]\n",
    "    reco_data = [d.to(device) for d in sampling.batch['reco']['data']]\n",
    "    reco_mask = [m.to(device) for m in sampling.batch['reco']['mask']]\n",
    "\n",
    "    print(f\"Hard data batch size: {hard_data[0].shape[0]}\")\n",
    "    print(f\"Reco data batch size: {reco_data[0].shape[0]}\")\n",
    "\n",
    "    # Number of samples per event\n",
    "    total_samples = sampling.N_sample  \n",
    "    batch_size = 10  # Number of samples per batch to avoid memory issues\n",
    "    num_batches = (total_samples + batch_size - 1) // batch_size  # Ensure full coverage\n",
    "\n",
    "    # Storage for results\n",
    "    accumulated_samples = [None, None]  \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx in tqdm(range(num_batches), desc=\"Sampling batches\", unit=\"batch\"):\n",
    "            # Determine the number of samples to generate in this batch\n",
    "            current_N = min(batch_size, total_samples - batch_idx * batch_size)\n",
    "\n",
    "            # Generate samples\n",
    "            batch_samples = transfermer_model.sample(\n",
    "                hard_data,\n",
    "                hard_mask,\n",
    "                reco_data,\n",
    "                reco_mask,\n",
    "                N=current_N\n",
    "            )\n",
    "\n",
    "            # Feature selection\n",
    "            jets_indices = [0, 1, 2, 3]  # ['pt', 'eta', 'phi', 'mass']\n",
    "            met_indices = [0, 2]         # ['pt', 'phi']\n",
    "\n",
    "            batch_samples[0] = batch_samples[0][..., jets_indices]  # Filter jet features\n",
    "            batch_samples[1] = batch_samples[1][..., met_indices]   # Filter MET features\n",
    "\n",
    "            # Accumulate results\n",
    "            if accumulated_samples[0] is None:\n",
    "                accumulated_samples[0] = batch_samples[0].cpu()\n",
    "                accumulated_samples[1] = batch_samples[1].cpu()\n",
    "            else:\n",
    "                accumulated_samples[0] = torch.cat((accumulated_samples[0], batch_samples[0].cpu()), dim=0)\n",
    "                accumulated_samples[1] = torch.cat((accumulated_samples[1], batch_samples[1].cpu()), dim=0)\n",
    "\n",
    "    # Convert final results to the expected format\n",
    "    transfermer_samples = accumulated_samples\n",
    "\n",
    "    # Debugging prints\n",
    "    num_items = len(transfermer_samples)\n",
    "    print(f\"Number of elements per sample: {num_items}\")\n",
    "    for i, sample in enumerate(transfermer_samples):\n",
    "        print(f\"Sample {i}: {sample.shape}\")\n",
    "\n",
    "    # Save the concatenated samples\n",
    "    save_samples(transfermer_samples, transfermer_samples_file)\n",
    "\n",
    "# 3mins 27s, 10 events, 10000 samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b604adc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "figures = sampling.make_sampling_plots(ParallelTransfusion_model,external_samples=transfermer_samples, cmap='RdPu', save_dir='sampling_plots/transfermer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc20a255",
   "metadata": {},
   "source": [
    "# Parallel Transfusion per event sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26816b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "PT_samples_file = \"PT_samples2.pt\"\n",
    "if os.path.exists(os.path.join(\"saved_samples\", PT_samples_file)):\n",
    "    PT_samples = load_samples(PT_samples_file)\n",
    "else:\n",
    "    device = ParallelTransfusion_model.device\n",
    "    sampling.set_idx(sampling.idx_to_monitor)\n",
    "    hard_data = [d.to(device) for d in sampling.batch['hard']['data']]\n",
    "    hard_mask = [m.to(device) for m in sampling.batch['hard']['mask']]\n",
    "    reco_data = [d.to(device) for d in sampling.batch['reco']['data']]\n",
    "    reco_mask = [m.to(device) for m in sampling.batch['reco']['mask']]\n",
    "\n",
    "    print(f\"Hard data batch size: {hard_data[0].shape[0]}\")\n",
    "    print(f\"Reco data batch size: {reco_data[0].shape[0]}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model = ParallelTransfusion_model.to(ParallelTransfusion_model.device)\n",
    "        PT_samples = model.sample(\n",
    "                            hard_data, hard_mask,\n",
    "                            reco_data, reco_mask,\n",
    "                            sampling.N_sample,\n",
    "                            sampling.steps,\n",
    "                            sampling.store_trajectories\n",
    "                        )\n",
    "    # Debugging prints\n",
    "    num_items = len(PT_samples)\n",
    "    print(f\"Number of elements per sample: {num_items}\")\n",
    "    for i, sample in enumerate(PT_samples):\n",
    "        print(f\"Sample {i}: {sample.shape}\")\n",
    "    save_samples(PT_samples, PT_samples_file)\n",
    "\n",
    "# 42mins 14s for 10 events, 10000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2b4682",
   "metadata": {},
   "outputs": [],
   "source": [
    "figures = sampling.make_sampling_plots(ParallelTransfusion_model,external_samples=PT_samples, cmap='BuGn', save_dir='sampling_plots/parallel_transfusion')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9260f69",
   "metadata": {},
   "source": [
    "# Transfer-CFM per event sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4d1837",
   "metadata": {},
   "outputs": [],
   "source": [
    "TransferCFM_samples_file = \"TransferCFM_samples2.pt\"\n",
    "if os.path.exists(os.path.join(\"saved_samples\", TransferCFM_samples_file)):\n",
    "    TransferCFM_samples = load_samples(TransferCFM_samples_file)\n",
    "else:\n",
    "    device = ParallelTransfusion_model.device\n",
    "    sampling.set_idx(sampling.idx_to_monitor)\n",
    "    hard_data = [d.to(device) for d in sampling.batch['hard']['data']]\n",
    "    hard_mask = [m.to(device) for m in sampling.batch['hard']['mask']]\n",
    "    reco_data = [d.to(device) for d in sampling.batch['reco']['data']]\n",
    "    reco_mask = [m.to(device) for m in sampling.batch['reco']['mask']]\n",
    "\n",
    "    print(f\"Hard data batch size: {hard_data[0].shape[0]}\")\n",
    "    print(f\"Reco data batch size: {reco_data[0].shape[0]}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model = TransferCFM_model.to(TransferCFM_model.device)\n",
    "        TransferCFM_samples = model.sample(\n",
    "                            hard_data, hard_mask,\n",
    "                            reco_data, reco_mask,\n",
    "                            sampling.N_sample,\n",
    "                            sampling.steps,\n",
    "                            sampling.store_trajectories\n",
    "                        )\n",
    "    # Debugging prints\n",
    "    num_items = len(TransferCFM_samples)\n",
    "    print(f\"Number of elements per sample: {num_items}\")\n",
    "    for i, sample in enumerate(TransferCFM_samples):\n",
    "        print(f\"Sample {i}: {sample.shape}\")\n",
    "    save_samples(TransferCFM_samples, TransferCFM_samples_file)\n",
    "\n",
    "# 11mins 25s for 10 events, 10000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7f8513",
   "metadata": {},
   "outputs": [],
   "source": [
    "figures = sampling.make_sampling_plots(TransferCFM_model,external_samples=TransferCFM_samples, cmap='BuPu', save_dir='sampling_plots/transferCFM')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdd913e",
   "metadata": {},
   "source": [
    "# Bias Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52943be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = transfermer_model.device\n",
    "\n",
    "transfermer_bias_samples_file = \"Transfermer_bias_samples.pt\"\n",
    "if os.path.exists(os.path.join(\"saved_samples\", transfermer_bias_samples_file)):\n",
    "    transfermer_bias_samples = load_samples(transfermer_bias_samples_file)\n",
    "else:\n",
    "    for batch_idx, batch in tqdm(enumerate(bias.loader),desc='Predict',disable=False,leave=True,total=min(bias.N_batch,len(bias.loader)),position=0):\n",
    "        if batch_idx >= bias.N_batch:\n",
    "            break\n",
    "\n",
    "        # Get parts #\n",
    "        hard_data = [data.to(device) for data in batch['hard']['data']]\n",
    "        hard_mask_exist = [mask.to(device) for mask in batch['hard']['mask']]\n",
    "        reco_data = [data.to(device) for data in batch['reco']['data']]\n",
    "        reco_mask_exist = [mask.to(device) for mask in batch['reco']['mask']]\n",
    "\n",
    "        # Sample #\n",
    "        with torch.no_grad():\n",
    "            transfermer_bias_samples = transfermer_model.sample(\n",
    "                hard_data, hard_mask_exist,\n",
    "                reco_data, reco_mask_exist,\n",
    "                bias.N_sample,\n",
    "            )\n",
    "            # Feature selection\n",
    "            jets_indices = [0, 1, 2, 3]  # ['pt', 'eta', 'phi', 'mass']\n",
    "            met_indices = [0, 2]         # ['pt', 'phi']\n",
    "\n",
    "            transfermer_bias_samples[0] = transfermer_bias_samples[0][..., jets_indices]  # Filter jet features\n",
    "            transfermer_bias_samples[1] = transfermer_bias_samples[1][..., met_indices]   # Filter MET features\n",
    "\n",
    "        save_samples(transfermer_bias_samples, transfermer_bias_samples_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb2161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "figs = bias.make_bias_plots(ParallelTransfusion_model,show=True,external_samples=transfermer_bias_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef537ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            # Generate samples\n",
    "            batch_samples = transfermer_model.sample(\n",
    "                hard_data,\n",
    "                hard_mask,\n",
    "                reco_data,\n",
    "                reco_mask,\n",
    "                N=current_N\n",
    "            )\n",
    "\n",
    "            # Feature selection\n",
    "            jets_indices = [0, 1, 2, 3]  # ['pt', 'eta', 'phi', 'mass']\n",
    "            met_indices = [0, 2]         # ['pt', 'phi']\n",
    "\n",
    "            batch_samples[0] = batch_samples[0][..., jets_indices]  # Filter jet features\n",
    "            batch_samples[1] = batch_samples[1][..., met_indices]   # Filter MET features\n",
    "\n",
    "            # Accumulate results\n",
    "            if accumulated_samples[0] is None:\n",
    "                accumulated_samples[0] = batch_samples[0].cpu()\n",
    "                accumulated_samples[1] = batch_samples[1].cpu()\n",
    "            else:\n",
    "                accumulated_samples[0] = torch.cat((accumulated_samples[0], batch_samples[0].cpu()), dim=0)\n",
    "                accumulated_samples[1] = torch.cat((accumulated_samples[1], batch_samples[1].cpu()), dim=0)\n",
    "\n",
    "    # Convert final results to the expected format\n",
    "    transfermer_samples = accumulated_samples\n",
    "\n",
    "    # Debugging prints\n",
    "    num_items = len(transfermer_samples)\n",
    "    print(f\"Number of elements per sample: {num_items}\")\n",
    "    for i, sample in enumerate(transfermer_samples):\n",
    "        print(f\"Sample {i}: {sample.shape}\")\n",
    "\n",
    "    # Save the concatenated samples\n",
    "    save_samples(transfermer_samples, transfermer_samples_file)\n",
    "\n",
    "# 3mins 27s, 10 events, 10000 samples\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mem-flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
